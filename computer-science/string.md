# String

* 문자열 
* 자료형 차이 이해를 위해 알아야 한다.
* 현재 유니코드를 사용해야 텍스트를 정확하게 저장할 수 있다.
* 프로그래밍 언어마다 문자열을 저장하는 자료형이 다르므로 해당 자료형이 차지하고 있는 바이트를 이해해야 한다.
* **유니코드**
  * Unicode
  * 전세계 모든 문자를 컴퓨터에서 일관되게 표현하고 다룰 수 있도록 설계된 산업 표준
  * 유니코드 협회에서 제정한다.
  * 현존하는 문자 인코딩 방법을 모두 유니코드로 교체하고자 한다.
    * 인코딩 
      * 부호화
      * 어떤 문자나 기호를 컴퓨터가 이용할 수 있는 신호로 만드는 것
      * 이 신호를 입력하는 인코딩과 문자를 해독하는 디코딩을 하기 위해서는 미리 정해진 기준을 바탕으로 입력과 해독이 처리되어야 한다. 
        * 문자셋
          * charset
          * 인코딩과 디코딩의 기준
          * 문자셋의 국제 표준이 유니코드이다.
  * ASCII를 확장한 형태
  * UTF-8 & UTF-16
    * UTF
      * Universal Coded Character Set + Transformation Format 
    * UTF-8
      * 유니코드 한 문자를 나타내기 위해 1byte에서 4byte까지 사용한다.
      * 가변 길이를 가지는 인코딩 방식이다.
      * 네트워크를 통해 전송되는 텍스트는 주로 UTF-8로 인코딩된다.
        * 사용된 문자에 따라 더 작은 크기의 문자열을 표현할 수 있기 때문이다.
      * 문자별 용량
        * ASCII 코드 : 1byte
        * 영어 외 글자 : 2, 3byte
        * 보조 글자 : 4byte
        * 이모지 : 4byte
      * 바이트 순서가 고정되어있다. 
    * UTF-16
      * 코드를 그대로 바이트로 표현할 수 있다.
      * 바이트 순서가 다양하다.
      * 대부분 16bit로 표현한다.
      * 이진법으로 표현된 숫자를 16bit로 그대로 사용한다.
      * 바이트 순서에 따라 UTF-16의 종류도 달라진다.
      * 한글의 경우 2byte를 차지한다. 
* **ASCII**
  * 영문 알파벳을 사용하는 대표적인 문자 인코딩
  * 7비트로 모든 영어 알파벳을 표현할 수 있다.
  * 52개의 영문 알파벳 대소문자, 10개 숫자, 32개 특수문자, 1개 공백 문자 포함